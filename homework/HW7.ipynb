{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0\n",
    "\n",
    "It is highly recommended that you work with your group to fully complete the Discussion assignments on 11/17, 11/19, and 11/24, as these will directly help with your project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "In your project, you are required to demonstrate the use of decision trees and multinomial logistic regression classifiers. Groups of three must also demonstrate the use of one additional model. In this homework assignment, you will write a detailed report that will largely fulfill this requirement. \n",
    "\n",
    "Choose one machine learning model, other than decision trees and multinomial logistic regression (unless you are a group of 2 -- see below). Some possibilities include, but are not limited to: \n",
    "\n",
    "- Support vector classifiers (`sklearn.svm.SVC`). Complexity parameter is called `gamma`. Higher values create more complex models)\n",
    "- K-nearest-neighbor classifiers (`sklearn.neighbors.KNeighborsClassifier`). Complexity parameter is called `n_neighbors`. Higher values create less complex models. When working with KNN models, it is helpful to standardize your data columns first. For this purpose, `sklearn.preprocessing.StandardScaler` can be used. \n",
    "- Multilayer perceptron classifier, a kind of neural network (`sklearn.neural_network.MLPClassifier`). The complexity is controlled by the number of neurons and layers, as specified by the `hidden_layer_sizes` parameter -- more neurons and layers correspond to more complex models. \n",
    "\n",
    "You should consult the documentation for these models, which is available online or via `?`. \n",
    "\n",
    "**Suggestion**: It is recommended, but not required, that you coordinate with your group members so that each of you explores a different model. It is similarly suggested, but not required, that each of you use different subsets of three columns so that you can each learn something about different parts of the data. You are encouraged to help each other out on all parts of this problem. \n",
    "\n",
    "#### Groups of 2\n",
    "\n",
    "If you are a group of 2, you are not required to use an additional model and may instead use multinomial logistic regression for this assignment. Please note this in your submission. \n",
    "\n",
    "- Multinomial logistic regression (`sklearn.linear_model.LogisticRegression`). The complexity is controlled by `C`, the inverse regularization strength. Larger values of `C` correspond to more complex models. If you demonstrate multinomial logistic regression for this problem, you should also demonstrate cross-validation to select a small feature set. That is, you should (a) skip step 2 below and (b) use CV to select a set of three features, including one qualitative feature and two quantitative ones. \n",
    "\n",
    "### Instructions\n",
    "\n",
    "Replicate and expand the pipeline from Discussion 15, substituting out decision trees for your chosen classifier. You may also choose a different set of three columns than the ones used in that Discussion activity. In particular, you should: \n",
    "\n",
    "1. **Load** the data. \n",
    "2. **Select no more than three predictor columns** of the data and the `Species` target column, discarding the others. Choose one qualitative predictor column (e.g. `Island`, `Sex`) and two quantitative predictor columns. \n",
    "2. **Split the data** into training and test sets. \n",
    "3. Write one or more functions to **clean and transform the data** as needed. You should add comments and function docstrings as appropriate to describe to your reader what you are doing and why. Apply your functions to the training and test sets. \n",
    "4. **Use cross-validation** to estimate an optimal complexity parameter for your model. \n",
    "5. Having selected an optimal complexity parameter, **evaluate your model on the test set.** \n",
    "6. **Inspect** a few instances in which your trained model gave the wrong answer on the test set. Explain why your model was \"tricked\" in this case? Create and comment on a confusion matrix -- [check Monday's lecture notes](https://nbviewer.jupyter.org/github/PhilChodrow/PIC16A/blob/master/content/ML/digits.ipynb) for an example. \n",
    "7. **Plot the [decision regions](https://nbviewer.jupyter.org/github/PhilChodrow/PIC16A/blob/master/live_lectures/live-lecture-22.ipynb)** for your model. The horizontal and vertical axes should be the two quantitative predictor variables that you selected. Create a separate plot for each possible value of the qualitative predictor variable that you selected. For example, if you chose `Sex` as your qualitative variable, you should show two plots, with the decision regions for Female and Male penguins separately. Add appropriate axis labels and any other measures required to make your plots look professional. Add commentary to contextualize the mistakes that your model made. \n",
    "\n",
    "Throughout, add helpful explanation for your reader. For example, you should explain the idea behind cross-validation; anything you are able to learn about how your model works; how to interpret the optimal complexity parameter; and why your model went wrong in certain cases.  \n",
    "\n",
    "### Specifications\n",
    "\n",
    "Your solution should **not** fit in a single code cell -- a good, readable, and adequately-explained solution will likely require at least one code cell for each of the eight steps above. Make sure that there is plenty of surrounding text explanation and comments. Add code cells and plenty of markdown cells as needed. You can also use section headers with `###` to organize your work. **Treat this problem as 50% coding assignment and 50% clearly-written lab report.**\n",
    "\n",
    "Your comments and explanation should be written to an imaginary reader who has never encountered the Palmer Penguins data set before, and knows less about machine learning than you do. Explain your steps. Why train-test split? Why cross-validation? Why decision regions? And so on. If you'd like, imagine that you are writing to a time-traveller version of you from two weeks ago. \n",
    "\n",
    "## Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
