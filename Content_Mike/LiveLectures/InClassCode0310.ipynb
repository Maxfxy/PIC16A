{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "penguins=pd.read_csv(\"palmer_penguins.csv\")\n",
    "titanic=pd.read_csv(\"titanic.csv\")\n",
    "url = \"https://philchodrow.github.io/PIC16A/datasets/gapminder.csv\"\n",
    "gapminder = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why do we keep cv=5?\n",
    "#No good reason\n",
    "#in real-world applications, commonly choose cv to between 5 and 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example pseudo code: \n",
    "\n",
    "## predict titatanic survival via decision tree\n",
    "\n",
    "split X,y into X_train,X_test, y_train, y_test\n",
    "\n",
    "train model on X_train,y_train with depth d\n",
    "\n",
    "score in on X_test, y_test\n",
    "\n",
    "Question: What value should we use for d??????\n",
    "\n",
    "Most obvious answer: try a bunch of d' see what works besst, i.e. do the two lines below for a bunch of different d's\n",
    "\n",
    "train model on X_train,y_train with depth d\n",
    "score in on X_test, y_test\n",
    "\n",
    "Claim: This is cheating - we are using the test data to pick our model\n",
    "\n",
    "Goal: get all of the benefits of cheatiing, without actually cheating\n",
    "\n",
    "Solution 1 is use a __validation set__ (not yet cross validation set)\n",
    "\n",
    "first split X,y into X_train,X_test, y_train, y_test\n",
    "\n",
    "then put test data \"in a safe\" dont touch it!\n",
    "\n",
    "split training data again\n",
    "\n",
    "X_train, y_train --> X_train_new, X_validation, y_train_new, y_validation\n",
    "\n",
    "Now, what we ARE allowed to do is train model on X_train_new for a bunch of different d's\n",
    "and \"test\" it on X_val, y_val, then from this we can pick what we think is the best d\n",
    "and try it on the test set\n",
    "\n",
    "So now, cross-validation is a better version of validation\n",
    "\n",
    "Still split into train and test, now for each d\n",
    "split randomly into train_new and val, and evaluate the model with depth = d\n",
    "split 80/20, 5 different times,\n",
    "\n",
    "doing something randomly 5 different times and taking the average \n",
    "makes the outcome more consistent and reliable\n",
    "\n",
    "split train into train1, train2, .... train5\n",
    "first let train5 be the validation, adn the other 4 be the actuall training\n",
    "then let train4 be the validation and....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
