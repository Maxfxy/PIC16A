{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: Handwritten Digit Classification\n",
    "\n",
    "How good is your handwriting? If you write a number like \"3\", is it clearly distinct from an \"8\"? \n",
    "\n",
    "In the early days of machine learning, one of the most famous problems was *handwritten image recognition*. The goal was to teach algorithms to automatically recognize digits. This is very handy, for example, in post offices that need to sort thousands of pieces of mail every day on the basis of hand-written postal codes. \n",
    "\n",
    "More importantly, it is an example of the very general problem of teaching a computer to look at an image an 'understand' what it is looking at. Once the machine learning community achieved very good sucess on digit recognition, success on other images followed shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most famous dataset of images is something called the MNIST dataset. However, in this video we will use a dataset of handwritten digits which sklearn supplies for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits=load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of object is digits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digits is a essentially a dictionary containing various information about our data. The data in this case is the predictor X. There are 64 columns in the data. Each column corresponds to a pixel in an 8x8 image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23fbe31f310>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=200\n",
    "pic=digits['data'][i]\n",
    "pic=pic.reshape(8,8)\n",
    "\n",
    "fig,ax=plt.subplots(1)\n",
    "ax.imshow(pic,cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `target` in this case is an `array` of integers corresponding to the true digit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits['target'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like complicated data, but as we'll see, we can achieve fairly strong predictive accuracy with tools that we've already learned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(digits.data,digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9547042564953013"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "m=LogisticRegression(random_state=0,solver='liblinear')\n",
    "cross_val_score(m,X_train,y_train,cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that looks fairly good! We suspect that we may be able to achieve accuracy of roughly 95% on the test data. Before we test this, let's try to understand where our model may be failing. This is an important part of the machine learning process -- when your model gives the wrong answer, you should **check why**. \n",
    "\n",
    "A good way to understand where a classification model is going wrong is via the *confusion matrix*. The confusion matrix is a simple visualization of the model's predictions against truth. To create a confusion matrix, we first need to explicitly extract the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 8, 0, ..., 1, 6, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X_train,y_train)\n",
    "y_train_pred=m.predict(X_train)\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[138,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 135,   0,   0,   0,   0,   0,   0,   2,   0],\n",
       "       [  0,   0, 130,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0, 134,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 143,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0, 126,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 129,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 131,   0,   0],\n",
       "       [  0,   2,   0,   1,   0,   0,   0,   0, 133,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   2, 141]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "c=confusion_matrix(y_train,y_train_pred)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `i,j`th entry of this array gives the number of times that the model predicted digit `j` when the digit was in fact `i\n",
    "`. Fortunately, we observe from the large numbers on the diagonal that the model is usually right, but not always! For example, there are cases in which the model predicts an 8 when the true digit was in fact a 1. Let's take a look at some of these cases. Boolean indexing gives us a convenient way to extract all of the incorrectly-classified digits: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 8, 1, 3, 8, 8, 8]), array([8, 9, 8, 8, 1, 1, 9]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=y_train!=y_train_pred\n",
    "mistakes=X_train[mask]\n",
    "mistake_labels=y_train[mask]\n",
    "mistake_preds=y_train_pred[mask]\n",
    "\n",
    "mistake_preds,mistake_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make one plot for each mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_plots=len(mistakes)\n",
    "\n",
    "fig,ax=plt.subplots(1,m_plots,figsize=(20,4))\n",
    "\n",
    "for i in range(m_plots):\n",
    "    ax[i].imshow(mistakes[i].reshape(8,8),cmap=plt.cm.binary)\n",
    "    ax[i].set(title=\"predicted:\" + str(mistake_preds[i]) + \" true: \" + str(mistake_labels[i]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is understandably confused! Many of these digits would be difficult to correctly classify even for a human. On the other hand, one could do better...\n",
    "\n",
    "\n",
    "For now, let's see how our model does on unseen data. Recall that we are expecting accuracy in the vicinity of 95%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9644444444444444"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that matches our expectations! We could also create a confusion matrix and visualize the errors on the test set, but that would be essentially all the same code, so we'll leave it as an exercise to the reader. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we do better? \n",
    "\n",
    "Yes! Modern handwritten digit classifiers use extremely complex neural networks to achieve over 99% accuracy, which is very impressive indeed. We don't need anything quite that fancy to significantly improve our own score.\n",
    "\n",
    "A **multilayer perceptron** is perhaps the simplest form of neural network. It works by training layers of \"neurons,\" which are very simple mathematical functions designed to adapt to nonlinearities in the data. Perceptrons with many layers of many neurons are able to flexibly fit a very wide variety of data; for this reason, however, they are also highly vulnerable to overfitting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(100, 100, 100, 100),\n",
       "              random_state=0, solver='lbfgs')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn = MLPClassifier(solver = \"lbfgs\",\n",
    "                   alpha = 1e-5, \n",
    "                   hidden_layer_sizes = (100, 100, 100, 100),\n",
    "                   random_state = 0)\n",
    "\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests are highly performant algorithms for regression and classification that work by training many different decision trees (which we've already seen) and treating them as a \"committee\" which then \"votes\" on the ultimate prediction. Until the advent of neural networks, random forests were one of the most widely performant algorithms in machine learning, and are still used in many applications. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "m = RandomForestClassifier(n_estimators = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9844444444444445"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X_train, y_train)\n",
    "m.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using random forests, we were able to reduce our error rate to less than 1.5% -- impressive! \n",
    "\n",
    "Note how easy and pleasant it is to work with the Scikit-learn interface -- we already knew how to use functions like `cross_val_score()`, `m.fit()`, and `m.score()`. All we needed to do was load up a different classifier model and instantiate it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kymatio.sklearn import Scattering2D\n",
    "\n",
    "scattering_transformer = Scattering2D(2, (8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = scattering_transformer(X_train.reshape(1347,8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=LogisticRegression(random_state=0,solver='liblinear')\n",
    "\n",
    "transformed_data=transformed_data.reshape(1347,81*2*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9740298507462686"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cross_val_score(m,transformed_data,y_train,cv=10).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9547042564953013"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(m,X_train,y_train,cv=10).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
