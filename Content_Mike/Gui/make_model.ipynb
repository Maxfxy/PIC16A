{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation for the Penguin Classifier App\n",
    "\n",
    "This notebook shows how I created the machine learning model used for the penguin classifier app shown in the lectures on graphical user interfaces. My approach is very simple -- I'm using a decision tree and skipping cross-validation. The resulting model is OK, but with cross-validation and more careful modeling decisions, I know that you can do much better!!   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/PhilChodrow/PIC16A/master/datasets/palmer_penguins.csv'\n",
    "penguins = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['Species'] = penguins['Species'].str.split().str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Body Mass (g)</th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Island</th>\n",
       "      <th>Species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Biscoe</th>\n",
       "      <th>Adelie</th>\n",
       "      <td>3709.659091</td>\n",
       "      <td>38.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gentoo</th>\n",
       "      <td>5076.016260</td>\n",
       "      <td>47.504878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Dream</th>\n",
       "      <th>Adelie</th>\n",
       "      <td>3688.392857</td>\n",
       "      <td>38.501786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinstrap</th>\n",
       "      <td>3733.088235</td>\n",
       "      <td>48.833824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Torgersen</th>\n",
       "      <th>Adelie</th>\n",
       "      <td>3706.372549</td>\n",
       "      <td>38.950980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Body Mass (g)  Culmen Length (mm)\n",
       "Island    Species                                     \n",
       "Biscoe    Adelie       3709.659091           38.975000\n",
       "          Gentoo       5076.016260           47.504878\n",
       "Dream     Adelie       3688.392857           38.501786\n",
       "          Chinstrap    3733.088235           48.833824\n",
       "Torgersen Adelie       3706.372549           38.950980"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins.groupby(['Island', 'Species'])[['Body Mass (g)', 'Culmen Length (mm)']].aggregate(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(penguins, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_penguins(data_df):\n",
    "    \"\"\"\n",
    "    prepare the penguins data set\n",
    "    first, we apply a LabelEncoder to the Species and Island columns\n",
    "    second, we remove all columns other than the three we'll use for \n",
    "    this exercise. \n",
    "    third, we remove rows with na values in any of the required\n",
    "    columns. \n",
    "    finally, we split into predictor and target variables. \n",
    "    \n",
    "    data_df: a row-subset of the penguins data frame\n",
    "    return: X, y, the cleaned predictor and target variables (both data frames)\n",
    "    \"\"\"\n",
    "    \n",
    "    # copy the original df to suppress warnings\n",
    "    df = data_df.copy()\n",
    "    \n",
    "    # apply label encoders to Species and Island columns\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df['Species'] = le.fit_transform(df['Species'])\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df['Island'] = le.fit_transform(df['Island'])\n",
    "    \n",
    "    # only need these columns\n",
    "    df = df[['Species', 'Island', 'Body Mass (g)', 'Culmen Length (mm)']]\n",
    "    # remove rows if they have NA in any of the needed columns\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # separate into predictor and target variables\n",
    "    X = df.drop(['Species'], axis = 1)\n",
    "    y = df['Species']\n",
    "    \n",
    "    return(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prep_penguins(train)\n",
    "X_test, y_test   = prep_penguins(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9593023255813954)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the model\n",
    "T = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "T.fit(X_train, y_train)\n",
    "T.score(X_train, y_train), T.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling\n",
    "\n",
    "Here is the new part: after creating the model, we *pickle* it. This saves its state, allowing us to load it into a new Python session without going through the hassle of downloading the data and training the model every time we want to use the app.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saves the model\n",
    "pickle.dump(T, open(\"model.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
